# VAE Principle Analysis

属于ML中的深度学习领域，一种经典的生成式模型--**Generative AI**

## original VAE(Variational Auto-Encoding)

**reference**: 
* Paper: `Kingma, Diederik P., 和Max Welling. 《Auto-Encoding Variational Bayes》. arXiv:1312.6114. 预印本, arXiv, 2022年12月13日. https://doi.org/10.48550/arXiv.1312.6114.`
* video: [Youtube-VAE](https://youtu.be/qJeaCHQ1k2w?si=n256PW_hdRBoqJng)


### Mathematics Foundations

**key words**: `Auto-encoding`, `Variational Bayes`

`Calculus of variations`：变分法，数学的一个分支，涉及将微积分方法应用于寻找依赖于另一个函数或曲线函数的最大值和最小值，是数学中处理泛函极值的核心方法。

`Functional`：泛函，泛函是定义域为函数集合、值域为实数（或复数）的 “函数的函数”，核心是对函数整体性质做映射。

### VAE 基本思想 

生成式模型与传统模型的区别在于，传统模型将输入映射到输出，而生成式模型直接生成输出，通常是重构合理的数据。

**VAE是一种经典的生成式模型。**

原始自编码器(AutoEncoder， AE)的由两部分组成：编码器`Encoder`和解码器`Decoder`。编码器将原始数据从原始分布空间映射到潜在空间中的潜在表示，解码器将潜在表示映射回真实的数据表示。

其基本思想是：将原始数据分布$P(x)$映射到潜在分布$P(z)$，其中$P(z)$所在的潜在空间`Latent space`中的低维潜在表示`Latent representation`可以理解为包含了数据核心特征的表示向量，当掌握了这个潜在表示的分布后，在潜在空间中按照潜在分布随机采样点（或是在实际数据映射到的潜在变量附近采样），输入解码器就可以得到看似是真实数据的重构数据。

然而AE事实上并不能很好的完成数据生成任务，因为潜在空间是不规则的，实际采样点只要偏离一点，重构的数据效果就不理想，看起来与真实数据差别较大。于是VAE方法提出一种假设，即潜在分布是一种标准分布$P(Z) \sim \mathcal{N}(\mu, \sigma^2)$, 当假设$Z$的先验分布$P(Z)$是这种形式时，其潜在空间就是有规则结构的，`organized`的，后续采样并解码时就能生成看起来更“真实”的数据。

于是这里我们用一个标准分布$Q(Z) \sim \mathcal{N}(\mu, \sigma^2)$去近似真实的潜在分布，通过变分方法估计参数$\mu, \sigma$, 最小化$Q(z)$和$P(z)$的`KL散度`（让这两个分布相似）。

由此VAE的训练目标可以拆分成两个部分：一部分是最原始的目的，生成看起来真实的数据；另一部分是让潜在分布尽可能与标准分布相似，核心是通过变分推断近似后验分布。

$$L(x) = E_{P(z|x)}[\log P(x|z)] + KL(Q(x|z) | P(z))$$

其中左半部分可以理解为**重构损失**，后半部分可以理解为**潜在空间正则化**。
实际计算中通过化简，损失也可写作

$$L(x) = L_2(x, x') + -\frac{1}{2}(1 + \log(\sigma^2) - \mu^2 - \sigma^2)$$

### VAE 训练过程

* 原始数据输入编码器得到潜在表示
* 按照潜在近似的后验分布$Q(z|x)P(x)$潜在空间采样点
* 得到的潜在空间样本点通过解码器得到生成的新数据

由于中间存在随机采样，导致无法使用梯度下降算法优化参数，引入一个随机变量$\epsilon \sim \mathcal{N}(0, 1)$，采样的点$z = \mu + \sigma \times \epsilon$

监督目标：
* 生成的数据与真实数据的差异（均方误差MSE）
* 中间的潜在分布与标准分布的差异（KL散度）

损失函数
$$L(x) = L_2(x, x') + -\frac{1}{2}(1 + \log(\sigma^2) - \mu^2 - \sigma^2)$$

### VAE 局限性

#### 生成效果上

采用VAE生成人脸数据，会出现只有人脸清晰，但是背景模糊的情况，后续发展出其它生成式模型解决了这种问题
* GAN
* Diffusion

#### 灵活性上
显然这里VAE并没有指定生成目标的能力，后续一些VAE变体针对指定生成结果的能力进行了改进
* CVAE：条件VAE，可以指定生成的类别
* $\beta$-VAE，引入可调整参数平衡可重构性和解耦能力？
* VQ-VAE：离散化潜在表示空间，得到更尖锐的生成数据

### 公式推导(待细化)

目标：最大化信念:$logP(x)$

信念的下界`ELOB`：$E_{Q(z|x)}[\log\frac{P(x,z)}{Q{z|x}}]$

化简即可得到损失函数